{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0EUPJOFtmmx4",
        "outputId": "5082c202-14cf-4cc8-c17b-f71151dc86ec"
      },
      "outputs": [],
      "source": [
        "# !git clone https://github.com/toyboy12345/deep-matching.git\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## (Strategy Proofness - First Order Stochastic Dominance)\n",
        "$$\n",
        "\\forall i\\in W\\cup F \\ \\forall \\succ_i \\forall \\succ_{-i} \\forall \\succ'_i \\forall j \\\\\n",
        "\\sum_{j'\\succeq j}(g_{ij'}(\\succ'_i,\\succ_{-i})-g_{ij'}(\\succ_i,\\succ_{-i})) \\leq 0\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## (Ex-ante Stability)\n",
        "$\\nexists (w,f)\\in W\\times F$ s.t. $\\exist f'\\ [g_{wf'}(\\succ)>0\\land f\\succ_w f']\\ \\exist w'\\ [g_{w'f}(\\succ)>0\\land w\\succ_f w']$\n",
        "\n",
        "## (Stability of Deterministic Matching)\n",
        "$$\n",
        "\\forall (w,f)\\in W\\times F \\ g_{wf}+\\sum_{f'\\succ_w f}g_{wf'}+\\sum_{w'\\succ_f w}g_{w'f}\\geq 1\n",
        "$$\n",
        "\n",
        "## (Ex-post Stability)\n",
        "A randomized matching is **ex-post stable** iff it can be decomposed into deterministic stable matchings.\n",
        "\n",
        "## (Fractionally Stable)\n",
        "$$\n",
        "\\forall (w,f)\\in W\\times F \\ g_{wf}+\\sum_{f'\\succ_w f}g_{wf'}+\\sum_{w'\\succ_f w}g_{w'f}\\geq 1\n",
        "$$\n",
        "\n",
        "### (Violation of Fractionally Stability)\n",
        "$$\n",
        "\\sum_\\succ\\sum_w\\sum_f\\max\\left\\{0,1-g_{wf}(\\succ)-\\sum_{w'\\succ_f w}g_{w'f}(\\succ)-\\sum_{f'\\succ_w f}g_{wf'}(\\succ)\\right\\}\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qE04wnKQjmBt"
      },
      "source": [
        "## (Primal)\n",
        "$$\n",
        "\\begin{align*}\n",
        "    \\min & \\sum_\\succ\\sum_w\\sum_f t_{wf}(\\succ)\\\\\n",
        "    \\text{s.t.} & \\sum_f g_{wf}(\\succ)\\leq 1 & \\forall\\succ\\forall w \\\\\n",
        "    & \\sum_w g_{wf}(\\succ)\\leq 1 & \\forall \\succ\\forall f\\\\\n",
        "    & t_{wf}(\\succ)\\geq 1-g_{wf}(\\succ)-\\sum_{w'\\succeq_f w}g_{w'f}(\\succ)-\\sum_{f'\\succeq_w f}g_{wf'}(\\succ) & \\forall\\succ\\forall w\\forall f\\\\\n",
        "    & \\sum_{f'\\succeq_wf}(g_{wf'}(\\succ_w',\\succ_{-w})-g_{wf'}(\\succ))\\leq 0 & \\forall\\succ\\forall w\\forall\\succ_{w}'\\forall f\\\\\n",
        "    & \\sum_{w'\\succeq_fw}(g_{w'f}(\\succ_f',\\succ_{-f})-g_{w'f}(\\succ))\\leq 0 & \\forall\\succ\\forall f\\forall\\succ_{f}'\\forall w\\\\\n",
        "    & g_{wf}(\\succ)\\geq 0,\\ t_{wf}(\\succ)\\geq 0 & \\forall\\succ\\forall w \\forall y\n",
        "\\end{align*}\n",
        "$$\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NTaRdV6po4Ne"
      },
      "source": [
        "## (Dual)\n",
        "$$\n",
        "\\begin{align*}\n",
        "    \\min & \\sum_\\succ\\left(\\sum_wx_w(\\succ)+\\sum_fy_f(\\succ)-\\sum_w\\sum_fz_{wf}(\\succ)\\right)\\\\\n",
        "    \\text{s.t.}  \n",
        "    & x_w(\\succ)+y_f(\\succ)-z_{wf}(\\succ)-\\sum_{f'\\prec_wf}z_{wf'}(\\succ)-\\sum_{w'\\prec_fw}z_{w'f}(\\succ)+\\sum_{\\succ_w'}\\\\sum_{f'\\prec_w'f}\\left(u_{wf'}(\\succ_w',\\succ_w,\\succ_{-w})-u_{wf'}(\\succ_w,\\succ_w',\\succ_{-w})\\right)+\\sum_{\\succ_f'}\\sum_{w'\\prec_f'w}\\left(v_{w'f}(\\succ_f',\\succ_f,\\succ_{-f})-v_{w'f}(\\succ_f,\\succ_f',\\succ_{-f})\\right)\\geq 0 & \\forall\\succ\\forall w\\forall f\\\\\n",
        "    & x_w(\\succ)\\geq 0,\\ y_f(\\succ)\\geq 0,\\ 0\\leq z_{wf}(\\succ)\\leq 1 & \\forall\\succ\\forall w\\forall f\\\\\n",
        "    & u_{wf}(\\succ'_w,\\succ_w,\\succ_{-w})\\geq 0 & \\forall\\succ\\forall w\\forall\\succ_w'\\forall f\\\\\n",
        "    & v_{wf}(\\succ'_f,\\succ_f,\\succ_{-f})\\geq 0 & \\forall\\succ\\forall f\\forall\\succ_f'\\forall w\n",
        "\\end{align*}\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "gXglOtmqFw_Z"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import time\n",
        "import logging\n",
        "import argparse\n",
        "import numpy as np\n",
        "from random import random\n",
        "import itertools\n",
        "from pathlib import Path\n",
        "\n",
        "sys.path.append(str(Path(\"primal_dual_matching.ipynb\").resolve().parent.parent))\n",
        "\n",
        "import torch\n",
        "import torch.nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from data import Data\n",
        "from dual_net import DualNet\n",
        "from dual_loss import *\n",
        "from dual_train import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "MxVOWUwXF0in"
      },
      "outputs": [],
      "source": [
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "lambd = np.ones((3,3))*0.001\n",
        "# lambd = cfg.lambd\n",
        "\n",
        "cfg = HParams(num_agents = 3,\n",
        "              device = device,\n",
        "              lambd = lambd,\n",
        "              rho = 0.1,\n",
        "              lagr_iter = 1000,\n",
        "              batch_size = 512)\n",
        "\n",
        "cfg.lr = 1e-4\n",
        "\n",
        "np.random.seed(cfg.seed)\n",
        "\n",
        "G = Data(cfg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hOlaPu4SF8EP",
        "outputId": "029af6c6-fc12-414c-f410-c0064bb09a64"
      },
      "outputs": [],
      "source": [
        "model = DualNet(cfg)\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        },
        "id": "Jq4duSuiF-wZ",
        "outputId": "39d62945-fb86-415d-ebda-c75bbb6d1bf6"
      },
      "outputs": [],
      "source": [
        "train_dual(cfg,G,model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UYu3VuLWB1Tu",
        "outputId": "c14eb259-dfb6-472b-c030-07f4c65868cd"
      },
      "outputs": [],
      "source": [
        "P,Q = G.generate_batch(1)\n",
        "p,q = torch.Tensor(P).to(device),torch.Tensor(P).to(device)\n",
        "model(p,q)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gQnTReGVH3Ml"
      },
      "outputs": [],
      "source": [
        "x,y,z,u,v = model(p,q)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bP9mxYZ8IEmy",
        "outputId": "709b38ea-e1e9-4385-8303-3fdf95f24be5"
      },
      "outputs": [],
      "source": [
        "compute_uloss(cfg,model,u,p,q)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zX6fA7NAH0dT",
        "outputId": "6a1048f4-aafb-4999-c1fe-370e726e3af2"
      },
      "outputs": [],
      "source": [
        "compute_loss(cfg,model,x,y,z,u,v,p,q,cfg.lambd,cfg.rho)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5w4HPcD37U2e"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import time\n",
        "import logging\n",
        "import argparse\n",
        "import numpy as np\n",
        "from random import random\n",
        "import itertools\n",
        "\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "sys.path.append(\"/content/deep-matching\")\n",
        "\n",
        "from data import Data\n",
        "from primal_net import PrimalNet\n",
        "from primal_loss import *\n",
        "from primal_train import *\n",
        "\n",
        "from baselines import RSD,DA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bRK4CV2T8KD0"
      },
      "outputs": [],
      "source": [
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "# lambd = np.ones((3,3))*1\n",
        "lambd = cfg.lambd\n",
        "\n",
        "cfg = HParams(num_agents = 3,\n",
        "              device = device,\n",
        "              lambd = lambd,\n",
        "              rho = 100,\n",
        "              lagr_iter = 1000,\n",
        "              batch_size = 512)\n",
        "\n",
        "cfg.lr = 1e-5\n",
        "\n",
        "np.random.seed(cfg.seed)\n",
        "\n",
        "G = Data(cfg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HcLWltJD8qd2",
        "outputId": "a4cc03b3-af10-44e1-9c6d-68dc27e5ca95"
      },
      "outputs": [],
      "source": [
        "model = PrimalNet(cfg)\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "U73iW-RO81Pl",
        "outputId": "6e1f7bc7-1df2-4f4f-aaca-eb5babf636bf"
      },
      "outputs": [],
      "source": [
        "train_primal(cfg,G,model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5FEOeb-ZgL03",
        "outputId": "b6dc6291-9177-4bc0-b515-e13242b2c1af"
      },
      "outputs": [],
      "source": [
        "a = torch.randn((2,3,3))\n",
        "a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YNnuOWBw_DQc"
      },
      "outputs": [],
      "source": [
        "torch.save(model,\"/content/deep-matching/models/primal/model_1.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pvYHK4oOXRmI"
      },
      "outputs": [],
      "source": [
        "if device == \"cpu\":\n",
        "    model2 = torch.load(\"/content/deep-matching/models/model_sp_verystable.pth\",map_location=torch.device('cpu'))\n",
        "else:\n",
        "    model2 = torch.load(\"/content/deep-matching/models/model_sp_verystable.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lLfosf1O6ns0",
        "outputId": "639b0624-e584-49b5-9ccb-b068bd4143f0"
      },
      "outputs": [],
      "source": [
        "P,Q = G.generate_batch(100)\n",
        "p,q = torch.Tensor(P).to(device),torch.Tensor(Q).to(device)\n",
        "r = model(p,q)\n",
        "r2 = model2(p,q)\n",
        "\n",
        "# print(r)\n",
        "# print(r2)\n",
        "# print(DA(p,q))\n",
        "# print(RSD(p,q))\n",
        "\n",
        "print(compute_spv_w(cfg,model,r,p,q).sum(),compute_spv_f(cfg,model,r,p,q).sum())\n",
        "print(compute_spv_w(cfg,model2,r2,p,q).sum(),compute_spv_f(cfg,model2,r2,p,q).sum())\n",
        "print(compute_spv_w(cfg,DA,DA(p,q),p,q).sum(),compute_spv_f(cfg,DA,DA(p,q),p,q).sum())\n",
        "print(compute_spv_w(cfg,RSD,RSD(p,q),p,q).sum(),compute_spv_f(cfg,RSD,RSD(p,q),p,q).sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJlYdW41X52H",
        "outputId": "d88781b4-6f34-4415-8ef7-6d2fa7acb23a"
      },
      "outputs": [],
      "source": [
        "print(compute_loss(cfg,model,model(p,q),p,q,cfg.lambd,cfg.rho))\n",
        "print(compute_loss(cfg,model2,model2(p,q),p,q,cfg.lambd,cfg.rho))\n",
        "print(compute_loss(cfg,DA,DA(p,q),p,q,cfg.lambd,cfg.rho))\n",
        "print(compute_loss(cfg,RSD,RSD(p,q),p,q,cfg.lambd,cfg.rho))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nw8-gMuPYizL"
      },
      "outputs": [],
      "source": [
        "from baselines import RSD,DA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QE6mlceJYVfa",
        "outputId": "58d31fb5-78d1-4cb5-d88a-292d0738dc66"
      },
      "outputs": [],
      "source": [
        "compute_loss(cfg,RSD,RSD(p,q),p,q,torch.Tensor(cfg.lambd).to(device),cfg.rho)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6uvzwnpY94ZW",
        "outputId": "8e239ae3-8d27-41c1-9ed3-db304c2f5f7d"
      },
      "outputs": [],
      "source": [
        "compute_t(r,p,q)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nqt5K6AO9D7s",
        "outputId": "d4bce18f-4ab3-4189-e6ac-52279052a6ae"
      },
      "outputs": [],
      "source": [
        "%%writefile deep-matching/primal_net.py\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class PrimalNet(nn.Module):\n",
        "    \"\"\" Neural Network Module for Matching \"\"\"\n",
        "    def __init__(self, cfg):\n",
        "        super(PrimalNet, self).__init__()\n",
        "        self.cfg = cfg\n",
        "        num_agents = self.cfg.num_agents\n",
        "        num_hidden_nodes = self.cfg.num_hidden_nodes\n",
        "\n",
        "        self.input_block = nn.Sequential(\n",
        "            # Input Layer\n",
        "            nn.Linear(2 * num_agents*num_agents, num_hidden_nodes),\n",
        "            nn.LeakyReLU(),\n",
        "\n",
        "            # Layer 1\n",
        "            nn.Linear(num_hidden_nodes, num_hidden_nodes),\n",
        "            nn.LeakyReLU(),\n",
        "\n",
        "            # Layer 2\n",
        "            nn.Linear(num_hidden_nodes, num_hidden_nodes),\n",
        "            nn.LeakyReLU(),\n",
        "\n",
        "            # Layer 3\n",
        "            nn.Linear(num_hidden_nodes, num_hidden_nodes),\n",
        "            nn.LeakyReLU(),\n",
        "\n",
        "            # Layer 4\n",
        "            nn.Linear(num_hidden_nodes, num_hidden_nodes),\n",
        "            nn.LeakyReLU())\n",
        "\n",
        "\n",
        "        # Output Layer\n",
        "        self.layer_out = nn.Linear(num_hidden_nodes, num_agents * num_agents)\n",
        "\n",
        "\n",
        "    def forward(self, p, q):\n",
        "        x = torch.stack([p, q], axis = -1)\n",
        "        x = x.view(-1, self.cfg.num_agents * self.cfg.num_agents * 2)\n",
        "        x = self.input_block(x)\n",
        "\n",
        "        r = self.layer_out(x)\n",
        "        r = r.view(-1, self.cfg.num_agents, self.cfg.num_agents)\n",
        "        r = F.softplus(r)\n",
        "        r = F.normalize(r, p = 1, dim = 1, eps=1e-8)\n",
        "\n",
        "        return r"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-UzfT6PMYV6",
        "outputId": "2618e78c-88a9-4206-e707-0f7e9254c10d"
      },
      "outputs": [],
      "source": [
        "%%writefile deep-matching/primal_loss.py\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from data import Data\n",
        "\n",
        "def compute_t(r, p, q):\n",
        "    wp = torch.where(p[:, :, None, :] - p[:, :, :, None]>0,1,0).to(torch.float)\n",
        "    wq = torch.where(q[:, :, None, :] - q[:, None, :, :]>0,1,0).to(torch.float)\n",
        "    t =  r + torch.einsum('bjc,bijc->bic', r, wq) + torch.einsum('bia,biac->bic', r, wp)  - 1\n",
        "    return t\n",
        "\n",
        "def compute_spv_w(cfg, model, r, p, q):\n",
        "    num_agents = cfg.num_agents\n",
        "    device = cfg.device\n",
        "    G = Data(cfg)\n",
        "\n",
        "    P,Q = p.to('cpu').detach().numpy().copy(),q.to('cpu').detach().numpy().copy()\n",
        "    spv_w = torch.zeros((num_agents,num_agents)).to(device)\n",
        "    for agent_idx in range(num_agents):\n",
        "        P_mis, Q_mis = G.generate_all_misreports(P, Q, agent_idx = agent_idx, is_P = True, include_truncation = False)\n",
        "        p_mis, q_mis = torch.Tensor(P_mis).to(device), torch.Tensor(Q_mis).to(device)\n",
        "        r_mis = model(p_mis.view(-1, num_agents, num_agents), q_mis.view(-1, num_agents, num_agents))\n",
        "        r_mis = r_mis.view(p.shape[0],-1,num_agents,num_agents)\n",
        "\n",
        "        r_mis_agent = r_mis[:,:,agent_idx,:]\n",
        "\n",
        "        r_agent = r[:,agent_idx,:]\n",
        "        r_agent = r_agent.repeat(1,r_mis_agent.shape[1]).view(r_mis_agent.shape[0],r_mis_agent.shape[1],r_mis_agent.shape[2])\n",
        "\n",
        "        for f in range(num_agents):\n",
        "            mask = torch.where(p[:,agent_idx,:]>=p[:,agent_idx,f].view(-1,1),1,0)\n",
        "            mask = mask.repeat(1,r_mis_agent.shape[1]).view(r_mis_agent.shape[0],r_mis_agent.shape[1],r_mis_agent.shape[2])\n",
        "            spv_w[agent_idx,f] = ((r_mis_agent - r_agent)*mask).sum(-1).relu().sum(-1).mean()\n",
        "    return spv_w\n",
        "\n",
        "def compute_spv_f(cfg, model, r, p, q):\n",
        "    num_agents = cfg.num_agents\n",
        "    device = cfg.device\n",
        "    G = Data(cfg)\n",
        "\n",
        "    P,Q = p.to('cpu').detach().numpy().copy(),q.to('cpu').detach().numpy().copy()\n",
        "    spv_f = torch.zeros((num_agents,num_agents)).to(device)\n",
        "    for agent_idx in range(num_agents):\n",
        "        P_mis, Q_mis = G.generate_all_misreports(P, Q, agent_idx = agent_idx, is_P = True, include_truncation = False)\n",
        "        p_mis, q_mis = torch.Tensor(P_mis).to(device), torch.Tensor(Q_mis).to(device)\n",
        "        r_mis = model(p_mis.view(-1, num_agents, num_agents), q_mis.view(-1, num_agents, num_agents))\n",
        "        r_mis = r_mis.view(p.shape[0],-1,num_agents,num_agents)\n",
        "\n",
        "        r_mis_agent = r_mis[:,:,:,agent_idx]\n",
        "\n",
        "        r_agent = r[:,:,agent_idx]\n",
        "        r_agent = r_agent.repeat(1,r_mis_agent.shape[1]).view(r_mis_agent.shape[0],r_mis_agent.shape[1],r_mis_agent.shape[2])\n",
        "\n",
        "        for w in range(num_agents):\n",
        "            mask = torch.where(q[:,:,agent_idx]>=q[:,w,agent_idx].view(-1,1),1,0)\n",
        "            mask = mask.repeat(1,r_mis_agent.shape[1]).view(r_mis_agent.shape[0],r_mis_agent.shape[1],r_mis_agent.shape[2])\n",
        "            spv_f[w,agent_idx] = ((r_mis_agent - r_agent)*mask).sum(-1).relu().sum(-1).mean()\n",
        "    return spv_f\n",
        "\n",
        "def compute_loss(cfg, model, r, p, q, lambd, rho):\n",
        "    t = compute_t(r,p,q)\n",
        "    spv_w = compute_spv_w(cfg,model,r,p,q)\n",
        "    spv_f = compute_spv_f(cfg,model,r,p,q)\n",
        "\n",
        "    constr_vio = spv_w+spv_f\n",
        "\n",
        "    loss = torch.sum(t) - 2*torch.sum(r) + (constr_vio*lambd).sum() + 0.5*rho*constr_vio.square().sum()\n",
        "\n",
        "    return loss,constr_vio.sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FWGOnDGaNDrI",
        "outputId": "e9f75cdb-77cb-44a6-924b-b764efe6cd53"
      },
      "outputs": [],
      "source": [
        "%%writefile deep-matching/primal_train.py\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "import logging\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from data import Data\n",
        "from primal_net import PrimalNet\n",
        "from primal_loss import *\n",
        "\n",
        "class HParams:\n",
        "    def __init__(self, num_agents = 3,\n",
        "                 batch_size = 1024, num_hidden_layers = 4, num_hidden_nodes = 256, lr = 5e-3, epochs = 50000,\n",
        "                 print_iter = 100, val_iter = 1000, num_val_batches = 200,\n",
        "                 prob = 0, corr = 0, seed = 0, device = \"cuda:0\",\n",
        "                 lambd = torch.ones((3,3)), rho = 1, lagr_iter = 100):\n",
        "        self.num_agents = num_agents\n",
        "        self.batch_size = batch_size\n",
        "        self.num_hidden_layers = 4\n",
        "        self.num_hidden_nodes = 256\n",
        "        self.lr = 5e-3\n",
        "        self.epochs = 50000\n",
        "        self.print_iter = 100\n",
        "        self.val_iter = 1000\n",
        "        self.save_iter = self.epochs - 1\n",
        "        self.num_val_batches = 200\n",
        "\n",
        "        # Higher probability => More truncation\n",
        "        self.prob = prob\n",
        "        # Correlation of rankings\n",
        "        self.corr = corr\n",
        "        # Run seed\n",
        "        self.seed = seed\n",
        "\n",
        "        self.device = device\n",
        "\n",
        "        self.lambd = lambd\n",
        "        self.rho = rho\n",
        "        self.lagr_iter = lagr_iter\n",
        "\n",
        "def train_primal(cfg, G, model, include_truncation = False):\n",
        "    # # File names\n",
        "    # root_dir = os.path.join(\"experiments\", \"agents_%d\"%(cfg.num_agents), \"corr_%.2f\"%(cfg.corr))\n",
        "    # log_fname = os.path.join(root_dir, \"LOG_%d_lambd_%f_prob_%.2f_corr_%.2f.txt\"%(cfg.seed, cfg.lambd, cfg.prob, cfg.corr))\n",
        "    # model_path = os.path.join(root_dir, \"MODEL_%d_lambd_%f_prob_%.2f_corr_%.2f\"%(cfg.seed, cfg.lambd, cfg.prob, cfg.corr))\n",
        "    # os.makedirs(root_dir, exist_ok=True)\n",
        "\n",
        "    # # Logger\n",
        "    logger = logging.getLogger()\n",
        "    logger.setLevel(logging.INFO)\n",
        "\n",
        "    num_agents = cfg.num_agents\n",
        "\n",
        "    if not logger.hasHandlers():\n",
        "        handler = logging.StreamHandler()\n",
        "        handler.setLevel(logging.INFO)\n",
        "        formatter = logging.Formatter('%(asctime)s:%(levelname)s:%(message)s')\n",
        "        handler.setFormatter(formatter)\n",
        "        logger.addHandler(handler)\n",
        "\n",
        "        handler = logging.FileHandler(log_fname, 'w')\n",
        "        handler.setLevel(logging.INFO)\n",
        "        formatter = logging.Formatter('%(asctime)s:%(levelname)s:%(message)s')\n",
        "        handler.setFormatter(formatter)\n",
        "        logger.addHandler(handler)\n",
        "\n",
        "    # Optimizer\n",
        "    opt = torch.optim.Adam(model.parameters(), lr = cfg.lr)\n",
        "    scheduler = torch.optim.lr_scheduler.MultiStepLR(opt, milestones=[10000,25000], gamma=0.5)\n",
        "\n",
        "    # Trainer\n",
        "    tic = time.time()\n",
        "    i = 0\n",
        "\n",
        "    lambd = cfg.lambd\n",
        "\n",
        "    while i < cfg.epochs:\n",
        "\n",
        "        # Reset opt\n",
        "        opt.zero_grad()\n",
        "        model.train()\n",
        "\n",
        "        # Inference\n",
        "        P, Q = G.generate_batch(cfg.batch_size)\n",
        "        p, q = torch.Tensor(P).to(cfg.device), torch.Tensor(Q).to(cfg.device)\n",
        "        r = model(p, q)\n",
        "\n",
        "        loss,constr_vio = compute_loss(cfg,model,r,p,q,torch.Tensor(lambd).to(cfg.device),cfg.rho)\n",
        "        if (i>0) and (i%cfg.lagr_iter == 0):\n",
        "            lambd += cfg.rho*constr_vio.item()\n",
        "            print(lambd)\n",
        "\n",
        "        loss.backward(retain_graph=True)\n",
        "\n",
        "        opt.step()\n",
        "        scheduler.step()\n",
        "        t_elapsed = time.time() - tic\n",
        "\n",
        "\n",
        "        # Validation\n",
        "        if i% cfg.print_iter == 0 or i == cfg.epochs - 1:\n",
        "            logger.info(\"[TRAIN-ITER]: %d, [Time-Elapsed]: %f, [Total-Loss]: %f\"%(i, t_elapsed, loss.item()))\n",
        "            logger.info(\"[CONSTR-Vio]: %f\"%(constr_vio.item()))\n",
        "\n",
        "        if (i>0) and (i % cfg.save_iter == 0) or i == cfg.epochs - 1:\n",
        "            torch.save(model, \"deep-matching/models/primal/model_tmp.pth\")\n",
        "\n",
        "        if ((i>0) and (i% cfg.val_iter == 0)) or i == cfg.epochs - 1:\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                val_loss = 0\n",
        "                val_constr_vio = 0\n",
        "                for j in range(cfg.num_val_batches):\n",
        "                    P, Q = G.generate_batch(cfg.batch_size)\n",
        "                    p, q = torch.Tensor(P).to(cfg.device), torch.Tensor(Q).to(cfg.device)\n",
        "                    r = model(p, q)\n",
        "                    loss,constr_vio = compute_loss(cfg,model,r,p,q,torch.Tensor(lambd).to(cfg.device),cfg.rho)\n",
        "                    val_loss += loss.item()\n",
        "                    val_constr_vio += constr_vio.item()\n",
        "                logger.info(\"\\t[VAL-ITER]: %d, [LOSS]: %f, [Constr-vio]: %f\"%(i, val_loss/cfg.num_val_batches, val_constr_vio/cfg.num_val_batches))\n",
        "\n",
        "        i += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dl8Exk_NNX9F"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
